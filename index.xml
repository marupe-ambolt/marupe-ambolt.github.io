<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Emily</title>
    <link>http://example.org/</link>
    <description>Recent content on Emily</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 Sep 2021 09:50:36 +0200</lastBuildDate>
    
	<atom:link href="http://example.org/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>API</title>
      <link>http://example.org/emily-intro/structure/api/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/emily-intro/structure/api/</guid>
      <description>The API contains endpoints that can be called by a user or another service to interact with the machine learning service implemented by the Emily project. As an example, let us have a look at the predict endpoint:
class PredictItem(BaseModel): sample: str model_path: str @app.post(&amp;#39;/api/predict&amp;#39;) def predict(item: PredictItem): return {&amp;#39;result&amp;#39;: emily.predict(item)} Here we can see that the predict endpoint is a POST request and is accessed through /api/predict. Furthermore, we see that it requires two parameters in the request body: a sample and a model path.</description>
    </item>
    
    <item>
      <title>Install Emily</title>
      <link>http://example.org/emily-intro/install/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/emily-intro/install/</guid>
      <description>This guide will show you how to install Emily.
Windows MacOS Ubuntu  First download the newest Emily release here. Run the emily-installer.exe file, which will present you with an installation wizard. Go through the steps of the installation wizard to finish the installation. During the installation, you will be asked about additional items to setup. Emily needs Docker and Visual Studio Code in order to work. You can choose to let Emily install them for you, or you can install them yourself if you prefer.</description>
    </item>
    
    <item>
      <title>Create Emily project</title>
      <link>http://example.org/emily-intro/build/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:36 +0200</pubDate>
      
      <guid>http://example.org/emily-intro/build/</guid>
      <description>An Emily project consists of a template, which is a number of Python files with boilerplate code that you can fill out and customise, and a Docker container, which is a virtual environment where software and libraries for machine learning are already installed. Emily makes sure that each project is run inside its own Docker container, which means that you do not need to install any machine learning software on your own computer.</description>
    </item>
    
    <item>
      <title>API</title>
      <link>http://example.org/deploy/structure/api/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/deploy/structure/api/</guid>
      <description>The API is how users and other applications will interact with your service. We therefore need to specify how this interaction will happen. By default, an Emily machine learning API has three endpoints specified in the api.py file related to machine learning:
 /api/train endpoint /api/evaluate endpoint /api/train endpoint  We see in the notebook that the data is taken from an online repository:
penguins = pd.read_csv(&amp;#34;https://github.com/allisonhorst/palmerpenguins/raw/5b5891f01b52ae26ad8cb9755ec93672f49328a8/data/penguins_size.csv&amp;#34;) Since this is the only dataset that we will use, we can remove dataset_path as an input to the /api/train/ and /api/evaluate/ endpoints.</description>
    </item>
    
    <item>
      <title>API test</title>
      <link>http://example.org/deploy/test/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/deploy/test/</guid>
      <description>Once you have set up your API, it is time to test that it actually works. There are multiple ways to do this, and you will see here three different tools for testing your API:
 Swagger UI Postman curl  First of all, you should run your API. In an emily project, you can do this by running the API script with python api.py inside the container. We will assume that you are running your API on http://localhost:4242.</description>
    </item>
    
    <item>
      <title>Emily</title>
      <link>http://example.org/emily-intro/structure/emily/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/emily-intro/structure/emily/</guid>
      <description>The Emily class is simply a wrapper class that instantiates a trainer, an evaluator, and a predictor, and makes these available for calling through the API.
def __init__(self): self.predictor = Predictor() # Creates instance of the Predictor class self.trainer = Trainer() # Creates instance of the Trainer class self.evaluator = Evaluator() # Creates instance of the Evaluator class def predict(self, request): &amp;#34;&amp;#34;&amp;#34; This function calls the __call__ function from the Predictor class in ml.</description>
    </item>
    
    <item>
      <title>Deploy</title>
      <link>http://example.org/deploy/deploy/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/deploy/deploy/</guid>
      <description>Deploying a service involves hosting it on a server or similar where it can be accessed by clients, apps, or other services. Once you have a server setup that you want to deploy to, Emily can help you with the actual deployment.
To deploy, run emily deploy server &amp;lt;project name&amp;gt;. First you will be asked which file to run when deployed. For Emily projects this is usually api.py. Next you must choose whether to use GPU functionality on the server you deploy on.</description>
    </item>
    
    <item>
      <title>Model</title>
      <link>http://example.org/deploy/structure/model/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/deploy/structure/model/</guid>
      <description>The choice of model is central to a machine learning project, since how to train, evaluate, and predict depends on the model. This choice should be implemented in the Model class, where you can customise your own model.
In the notebook we see the following snippet of code where a linear regression model is defined.
model_ols = LinearRegression() In the ml/model.py file, we therefore specify that our model should be a LinearRegression model:</description>
    </item>
    
    <item>
      <title>Model</title>
      <link>http://example.org/emily-intro/structure/model/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/emily-intro/structure/model/</guid>
      <description>The model is where the type of machine learning model to be used in the Emily project is specified. This should be done by letting the model class inherit from whichever machine learning model you wish to use in the project. For example, if you want to use a linear regression model, you can use the LinearRegression class from scikit-learn:
class Model(sklearn.linear_model.LinearRegression): When we forward a sample to the model, it should make a prediction.</description>
    </item>
    
    <item>
      <title>Share Emily projects</title>
      <link>http://example.org/emily-intro/share/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/emily-intro/share/</guid>
      <description>When working in a team, it is important that machine learning projects can be shared among team members. Emily supports easy sharing of projects, and integrates with version control software such as git. Since Emily projects are run in Docker containers, you do not need to worry about having the correct libraries or versions installed on the computer of each team member, because Emily makes sure to start the project in a container which has all the required libraries installed.</description>
    </item>
    
    <item>
      <title>Trainer</title>
      <link>http://example.org/emily-intro/structure/trainer/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/emily-intro/structure/trainer/</guid>
      <description>The trainer implements the behaviour for training a model. The steps for doing so are the following:
 Load training data Preprocess training data Train using the training data Save the trained model  1. Load training data In order to load the training data, the _load_train_data method must be implemented. For example, the training data can be loaded by reading a csv file using pandas:
def _load_train_data(self, dataset_path): train_dataset = pandas.</description>
    </item>
    
    <item>
      <title>Training</title>
      <link>http://example.org/deploy/structure/train/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/deploy/structure/train/</guid>
      <description>The Trainer class should implement the behaviour for training a model based on the training dataset.
In the ml/trainer.py file, we can do away with any mention of the dataset_path variable, since we removed this from the /api/train/ endpoint.
_load_train_data method We first implement the _load_train_data() method, which, as the name suggests, loads the training data. To do this, we first look at the notebook and see that the data is read from a github page using the pandas library:</description>
    </item>
    
    <item>
      <title>Evaluating</title>
      <link>http://example.org/deploy/structure/eval/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/deploy/structure/eval/</guid>
      <description>The Evaluator class should implement the behaviour for evaluating a trained model based on the testing dataset.
In the ml/evaluator.py file, we can also remove mentions of the dataset_path variable. Many of the steps for evaluating are the same as for training, so we import the same libraries:
import pandas as pd from sklearn.model_selection import train_test_split from ml.model import Model _load_test_data method In order to load the test data, we do essentially the same as when loading the train data, except now we return the test data instead of the train data:</description>
    </item>
    
    <item>
      <title>Evaluator</title>
      <link>http://example.org/emily-intro/structure/evaluator/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/emily-intro/structure/evaluator/</guid>
      <description>The evaluator implements the behaviour for evaluating a model. The steps for doing so are the following:
 Load the model Load the test data Preprocess the test data Evaluate the model on the test data  1. Load the model In order to load the model, use the load_model method on the model class. Here is how this is done by default in the template:
if model_path != self.model_path: self.</description>
    </item>
    
    <item>
      <title>Predicting</title>
      <link>http://example.org/deploy/structure/predict/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/deploy/structure/predict/</guid>
      <description>The Predictor class should implement the behaviour for predicting a new sample based on a trained model.
As a first step, we import the numpy library, which we will use later.
import numpy as np from ml.model import Model _preprocess method The _preprocess() method should take as input the features we use to predict.
 Flipper length Body mass Species  Then the method creates an array and puts the sample input into that array, and finally standardises it using the same scaler as previously, to make sure that the sample is scaled in the same way as the training data.</description>
    </item>
    
    <item>
      <title>Predictor</title>
      <link>http://example.org/emily-intro/structure/predictor/</link>
      <pubDate>Mon, 27 Sep 2021 09:50:28 +0200</pubDate>
      
      <guid>http://example.org/emily-intro/structure/predictor/</guid>
      <description>The predictor implements the behaviour for using a model to make a prediction based on a sample. The steps for doing so are the following:
 Load the model Preprocess the sample Make the prediction Postprocess the prediction  1. Load the model In order to load the model, use the load_model method on the model class. Here is how this is done by default in the template:
if model_path !</description>
    </item>
    
  </channel>
</rss>